{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Storage Service Demo\n",
    "This is intended to be run on the Python 2 kernel.   \n",
    "If you have not installed azure and azure-storage un-comment the pip below and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage==0.32.0\n",
      "  Downloading https://files.pythonhosted.org/packages/60/59/916c26b9d09094fbaee0944ae70e286e21c4356a2a0f5fdaa0fcda923972/azure_storage-0.32.0-py2-none-any.whl (160kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 2.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil (from azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 2.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting azure-common (from azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/1e/cfe7987493242e8b9ead309cfd76fc500c38bbefe192192b813325d289f3/azure_common-1.1.27-py2.py3-none-any.whl\n",
      "Collecting requests (from azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting futures (from azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting azure-nspkg (from azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/95/af354f2f415d250dafe26a5d94230558aa8cf733a9dcbf0d26cd61f5a9b8/azure_nspkg-3.0.2-py2-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil->azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests->azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/cd/1e2ec680ec7b09846dc6e605f5a7709dfb9d7128e51a026e7154e18a234e/urllib3-1.26.5-py2.py3-none-any.whl (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 5.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5 (from requests->azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/1b/0a0dece0e8aa492a6ec9e4ad2fe366b511558cdc73fd3abc82ba7348e875/certifi-2021.5.30-py2.py3-none-any.whl (145kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 4.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2 (from requests->azure-storage==0.32.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl (178kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: six, python-dateutil, azure-nspkg, azure-common, urllib3, idna, certifi, chardet, requests, futures, azure-storage\n",
      "  Found existing installation: six 1.10.0\n",
      "    Uninstalling six-1.10.0:\n",
      "      Successfully uninstalled six-1.10.0\n",
      "  Found existing installation: python-dateutil 2.6.0\n",
      "    Uninstalling python-dateutil-2.6.0:\n",
      "      Successfully uninstalled python-dateutil-2.6.0\n",
      "  Found existing installation: certifi 2017.1.23\n",
      "\u001b[31m    DEPRECATION: Uninstalling a distutils installed project (certifi) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n",
      "    Uninstalling certifi-2017.1.23:\n",
      "      Successfully uninstalled certifi-2017.1.23\n",
      "  Found existing installation: requests 2.13.0\n",
      "    Uninstalling requests-2.13.0:\n",
      "      Successfully uninstalled requests-2.13.0\n",
      "  Found existing installation: futures 3.0.5\n",
      "    Uninstalling futures-3.0.5:\n",
      "      Successfully uninstalled futures-3.0.5\n",
      "Successfully installed azure-common-1.1.27 azure-nspkg-3.0.2 azure-storage-0.32.0 certifi-2021.5.30 chardet-4.0.0 futures-3.3.0 idna-2.10 python-dateutil-2.8.1 requests-2.25.1 six-1.16.0 urllib3-1.26.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-storage==0.32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello atMon Jun  7 04:12:32 2021\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import azure.storage\n",
    "from azure.storage.table import TableService, Entity\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "import time\n",
    "print(\"hello at\" + time.asctime(time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "follow the instructions in the book to create a storage account.   the one used here is \"tutorial\", but you will want to pick something else and replace that name everywhere below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account = 'databaseyue'\n",
    "block_blob_service = BlockBlobService(account_name=account,\n",
    "    account_key='H8QILZR9BRApAKjdvy8Rphn0BXm4SWkYUO/+0w7FUlqaB50jl9Ihdt9jKK2u62WzY+VrrfmzZWvbnCSH4XDYAg==')\n",
    "block_blob_service.create_container('datacont', \n",
    "                                    public_access=PublicAccess.Container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_service = TableService(account_name=account, \n",
    "                             account_key='H8QILZR9BRApAKjdvy8Rphn0BXm4SWkYUO/+0w7FUlqaB50jl9Ihdt9jKK2u62WzY+VrrfmzZWvbnCSH4XDYAg==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table created\n"
     ]
    }
   ],
   "source": [
    "if table_service.create_table('DataTable'):\n",
    "    print(\"table created\")\n",
    "else:\n",
    "    print(\"table already there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need a directory with a csv file.  For example\n",
    "\n",
    "'experiment1', '1', '3/15/2002', 'exp1', 'this is the comment'\n",
    "\n",
    "'experiment1', '2', '3/15/2002', 'exp2', 'this is the comment2'\n",
    "\n",
    "'experiment2', '3', '3/16/2002', 'exp3', 'this is the comment3'\n",
    "\n",
    "'experiment3', '4', '3/16/2002', 'exp4', 'this is the comment233'\n",
    "\n",
    "now you need a directory datafiles that has four blobs of any type.  call them exp1, exp2, exp3, exp4.  \n",
    "we have one ready for you if you are using the tutorial container. It is stored in /datadir.\n",
    "If you are running this somewhere else you will need to make your own.  \n",
    "let's see what is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['experiment1', ' id1', ' 12/1/2016', 'a.jpg', ' \"here is a view of what is to be made\"']\n",
      "['experiment1', ' id2', ' 12/3/2016', 'b.jpg', ' \"map rededuce picture\"']\n",
      "['experiment2', ' id3', ' 12/4/2016', 'c.jpg', ' \"sample notebook\"']\n",
      "['experiment3', ' id4', ' 12/5/2016', 'd.jpg', ' \"workers\"']\n",
      "['experiment1', ' id5', ' 12/6/2016', 'e.jpg', ' \"bio samples\"']\n"
     ]
    }
   ],
   "source": [
    " with open('/datadir/experiments.csv', 'rb') as csvfile:\n",
    "    csvf = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for item in csvf:\n",
    "        print(item)\n",
    "#reading the csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code below will upload the data blobs into the container \"datacont\", then create the url and upload the metadata into the table \"DataTable\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['experiment1', ' id1', ' 12/1/2016', 'a.jpg', ' \"here is a view of what is to be made\"']\n",
      "['experiment1', ' id2', ' 12/3/2016', 'b.jpg', ' \"map rededuce picture\"']\n",
      "['experiment2', ' id3', ' 12/4/2016', 'c.jpg', ' \"sample notebook\"']\n",
      "['experiment3', ' id4', ' 12/5/2016', 'd.jpg', ' \"workers\"']\n",
      "['experiment1', ' id5', ' 12/6/2016', 'e.jpg', ' \"bio samples\"']\n"
     ]
    }
   ],
   "source": [
    " with open('/datadir/experiments.csv', 'rb') as csvfile:\n",
    "    csvf = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for item in csvf:\n",
    "        print item\n",
    "        block_blob_service.create_blob_from_path(\n",
    "            'datacont', item[3],\n",
    "            \"/datadir/\"+item[3]\n",
    "            )\n",
    "#read every single line of csv file and put the jpg image into a data container as a blob\n",
    "        url = \"https://\"+account+\".blob.core.windows.net/datacont/\"+item[3]\n",
    "#create a link to these blobs within the data table \n",
    "        metadata_item = {'PartitionKey': item[0], 'RowKey': item[1], \n",
    "                 'description' : item[4], 'date' : item[2], 'url':url} \n",
    "        table_service.insert_entity('DataTable', metadata_item)\n",
    "#creating the entry of the data table, including the url link to each blob within the data table\n",
    "\n",
    "\n",
    "#moving tbe jpg files to the blob(datacont,data container)\n",
    "#upload metadata_item to data table\n",
    "#using the csv files and jpg files locally, and store the csv files as a data table, store the jpg pictures as blobs\n",
    "#connect the table with blobs, and connect them with csv file on the local machine by a url link\n",
    "#this program wont work unless I interact with the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's do a querry for experiment1 and project onto the urls.  it should print the urls created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://databaseyue.blob.core.windows.net/datacont/a.jpg\n",
      "https://databaseyue.blob.core.windows.net/datacont/b.jpg\n",
      "https://databaseyue.blob.core.windows.net/datacont/e.jpg\n"
     ]
    }
   ],
   "source": [
    "tasks = table_service.query_entities('DataTable', filter=\"PartitionKey eq 'experiment1'\", select='url')\n",
    "for task in tasks:\n",
    "    print(task.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look somethink like\n",
    "\n",
    "https://escistore.blob.core.windows.net/datacont/exp1\n",
    "\n",
    "https://escistore.blob.core.windows.net/datacont/exp2\n",
    "\n",
    "try clicking on the links in your output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next download the \"azure storage explorer\" and look at you table.\n",
    "\n",
    "You will need to add the account with the key to the storage explore. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
